#==============================================
# DEDUPE DATA
# - here, we're actually removing the rows
#   using distinct()
# - note: this is the quick-and-dirty
#   way of removing dupes
# - we could also do this manually to
#   have more control over exactly which of the
#   duplicates get removed
#==============================================
df.car_0_60_times  <- distinct(df.car_0_60_times ,car_full_nm, .keep_all = T)
df.car_engine_size <- distinct(df.car_engine_size ,car_full_nm, .keep_all = T)
df.car_horsepower  <- distinct(df.car_horsepower ,car_full_nm, .keep_all = T)
df.car_top_speed   <- distinct(df.car_top_speed ,car_full_nm, .keep_all = T)
df.car_torque      <- distinct(df.car_torque ,car_full_nm, .keep_all = T)
df.car_power_to_weight <- distinct(df.car_power_to_weight, car_full_nm, .keep_all = T)
#================================
# RE-INSPECT DUPES
# -are the dupes removed? (Yes.)
#================================
df.car_top_speed %>% filter(car_full_nm == "Chevrolet Chevy II Nova SS 283 V8 Turbo Fire - [1964]")
df.car_top_speed %>% filter(car_full_nm == "Koenigsegg CCX 4.7 V8 Supercharged - [2006]")
df.car_top_speed %>% filter(car_full_nm == "Pontiac Bonneville 6.4L V8 - [1960]")
# examine length
nrow(df.car_horsepower)       # 1578  * This is the longest, and the most 'important'
#         so we'll use it as the 'base' table
#         as we start to join the datasets all together
nrow(df.car_torque)           # 1577
nrow(df.car_0_60_times)       # 398
nrow(df.car_engine_size)      # 1576
nrow(df.car_top_speed)        # 1570
nrow(df.car_power_to_weight)  # 1578
#=================================================
# JOIN DATA
# - df.car_specs is sort of a master dataset
# - the first join joins two of the datasets
# - each additional dataset appends new variables
#   from the newly joined data
#=================================================
#---------------------------------------------------------------------------------
# JOIN
# - we're joining the data frames together, 2 at a time
# - note that df.car_horsepower is the first dataset in the first left_join()
#   ... this is because we just identified it as the longest/most-important table
#       which we can use as the foundation of our new master-dataset
#---------------------------------------------------------------------------------
df.car_specs <- left_join(df.car_horsepower, df.car_torque, by = "car_full_nm")      # count after join: 1578
df.car_specs <- left_join(df.car_specs, df.car_0_60_times, by = "car_full_nm")   # count after join: 1578
df.car_specs <- left_join(df.car_specs, df.car_engine_size, by = "car_full_nm")  # count after join: 1578
df.car_specs <- left_join(df.car_specs, df.car_top_speed, by = "car_full_nm")    # count after join: 1578
df.car_specs <- left_join(df.car_specs, df.car_power_to_weight, by = "car_full_nm") # count after join: 1578
#--------------------------
# RE-EXAMINE DUPES
# - they should be gone ...
#--------------------------
df.car_specs %>% group_by(car_full_nm) %>% summarise(count = n()) %>% filter(count != 1)
# A tibble: 0 Ã— 2
# ... with 2 variables: car_full_nm <chr>, count <int
#
# i.e., 0 duplicate records
#----------------
# Re-inspect data
#----------------
glimpse(df.car_specs)
# Observations: 1,578
# Variables: 11
#  car_full_nm                  <chr> "Bugatti Veyron 8.0 litre W16 Super Sport - [2010]", "...
#  horsepower_bhp               <int> 1184, 1184, 1183, 1124, 1120, 1100, 1030, 1016, 1004, ...
#  rpm_horsepower_measure_point <int> 6400, 6400, 6950, 7100, 7850, 2700, 6500, 7100, 7000, ...
#  torque_lb_ft                 <int> NA, 1106, 1094, 885, 774, 885, 972, 811, 796, 922, 711...
#  rpm_torque_measure_point     <int> NA, 3000, 6150, 4100, 5970, 4100, 4200, 4100, 5600, 22...
#  car_0_60_time_seconds        <dbl> 2.5, 2.5, 2.8, 2.9, 2.9, 2.9, 2.5, 2.8, 2.9, 2.7, 3.0,...
#  engine_size_cc               <chr> "7993", "7993", "6348", "5032", "4000", "5032", "6162"...
#  engine_size_ci               <dbl> 487.7, 487.7, 387.3, 307.0, 244.0, 307.0, 376.0, 307.0...
#  top_speed_mph                <int> 258, 255, 273, 273, 256, 261, 260, 249, 254, 252, 255,...
#  top_speed_kph                <int> 415, 410, 439, 439, 411, 420, 418, 400, 408, 405, 410,...
#  horsepower_per_ton_bhp       <dbl> 644.1, 594.9, 946.4, 794.3, 832.0, 766.5, 844.2, 718.0...
#
# NOTE: engine_size_cc was incorrectly read in as a chr
#       we'll need to manually change it
# You can look at this variable in R-Studio
#=============================
# RE-CAST VAR
#  engine_size_cc: chr -> int
#=============================
df.car_specs <- mutate(df.car_specs, engine_size_cc = as.integer(engine_size_cc))
#===================
# ADD NEW VARIABLES
#===================
#------------------------
# NEW VAR: year
# - we will use str_sub() to strip the year out of the
#------------------------
#df.car_specs <- mutate(df.car_specs, year = sub(".*\\[([0-9]{4})\\]","\\1",car_full_nm))
# TEST
df.car_specs$car_full_nm %>% str_sub(-5,-2) # LOOKS GOOD!
# CREATE VAR
df.car_specs  <- mutate(df.car_specs, year = str_sub(car_full_nm, -5, -2)) # %>% glimpse()
# INSPECT
glimpse(df.car_specs)
# RECAST 'year' AS FACTOR
df.car_specs$year <- df.car_specs$year %>% as.factor()
# EXAMINE LEVELS
# - note: the factor levels are in order
levels(df.car_specs$year)
#----------------
# NEW VAR: decade
#----------------
df.car_specs <- mutate(df.car_specs,
decade = as.factor(
ifelse(str_sub(df.car_specs$year,1,3) == '193','1930s',
ifelse(str_sub(df.car_specs$year,1,3) == '194','1940s',
ifelse(str_sub(df.car_specs$year,1,3) == '195','1950s',
ifelse(str_sub(df.car_specs$year,1,3) == '196','1960s',
ifelse(str_sub(df.car_specs$year,1,3) == '197','1970s',
ifelse(str_sub(df.car_specs$year,1,3) == '198','1980s',
ifelse(str_sub(df.car_specs$year,1,3) == '199','1990s',
ifelse(str_sub(df.car_specs$year,1,3) == '200','2000s',
ifelse(str_sub(df.car_specs$year,1,3) == '201','2010s',"ERROR"
)))))))))
)
)
# INSPECT decade
# - note: the levels are in order
levels(df.car_specs$decade)
glimpse(df.car_specs) # 'decade' is a factor var ... good.
# CHECK:
# - are the decades coded correctly?
# - this code will show all the combinations of
#   year and decade
# - we will visually inspect the output
df.car_specs %>%
select(year,decade) %>%
group_by(year,decade) %>%
summarize(dummy = 1) %>%
print(n = Inf)
#--------
# INSPECT
#--------
glimpse(df.car_specs)
#-------------------------------
# NEW VAR: make_nm
#  (i.e., the "make" of the car;
#  the "brand name" of the car)
#-------------------------------
#df.car_specs <- mutate(df.car_specs, make_nm = gsub(" .*$","", df.car_specs$car_full_nm))
df.car_specs <- mutate(df.car_specs, make_nm = str_replace(df.car_specs$car_full_nm, " .*$","") %>% factor())
# CHECK UNIQUE VALUES
# - do these car makes look correct? (Yes)
# - anything unusual? (No)
unique(df.car_specs$make_nm)
#--------------------------
# NEW VAR: car_weight_tons
#--------------------------
df.car_specs <- mutate(df.car_specs, car_weight_tons = horsepower_bhp / horsepower_per_ton_bhp)
#-------------------------
# NEW VAR: torque_per_ton
#-------------------------
df.car_specs <- mutate(df.car_specs, torque_per_ton = torque_lb_ft / car_weight_tons)
#========================================
# INSPECT DATA
#  - quick checks to make sure that
#    the variables were created properly
#========================================
# head(df.car_specs)
glimpse(df.car_specs)
#------------------------------
# Frequency table (AGGREGATE)
#  - decade
#------------------------------
# CHECK 'decade' variable
df.car_specs %>%
group_by(decade) %>%
summarize(count = n())
# decade count
# 1  1930s     2
# 2  1940s     7
# 3  1950s    57
# 4  1960s   143
# 5  1970s   125
# 6  1980s   154
# 7  1990s   262
# 8  2000s   526
# 9  2010s   302
#------------------------------
# Frequency table (AGGREGATE)
#  - make
#------------------------------
df.car_specs %>%
group_by(make_nm) %>%
summarise(make_count = length(make_nm)) %>%
arrange(desc(make_count))
# note: the list of car makes is too long so the output hasn't
#       been added here
glimpse(df.car_specs)
# EOF
library(tidyverse)
head(df.car_specs)
glimpse(df.car_specs)
ggplot(data = df.car_specs, aes(x = horsepower_bhp)) +
?geom_histogram()
library(gbm)
install.packages("gbm")
install.packages("randomForest")
install.packages("Rtsne")
library(randomForest)
library(gbm)
library(Rtsne)
?gbm
iris
dataset <- iris
head(dataset)
tail(dataset)
dim(dataset)
str(dataset)
levels(dataset$Species)
names(dataset)
glimpse(dataset)
library(dplyr)
glimpse(dataset)
summary(dataset)
mean(dataset)
head(dataset)
mean(dataset$Sepal.Length)
levels(dataset$Species)
names(dataset)
x <- dataset$Sepal.Length
y <- dataset$Sepal.Width
dim(dataset)
str(dataset)
tail(dataset)
x <- dataset$Sepal.Length
y <- dataset$Sepal.Width
mean(dataset$Sepal.Length)
median(dataset$Sepal.Length)
sd(x)
var(y)
cor(x, y)
cov(x, y)
z <- c(1,2,3,4,5,NA)
mean(z)
mean(z, na.rm = T)
mean(z, na.rm = F)
T
mean(z, na.rm = T)
summary(dataset)
str(dataset)
dataset_2 <- dataset[1:4]
View(dataset_2)
dataset_2 <- dataset[1:4]
mean(datast_2)
mean(dataset_2)
str(dataset_2)
str(dataset_2)
mean(dataset_2)
mean(dataset_2)
dframe
mean(dataset_2)
mean(dataset_2, na.rm = T)
dataset_2 <- c(x,y,z)
mean(dataset_2)
mean(dataset_2,na.rm =T)
dataset_2 <- dataset[1:4]
mean(dataset_2)
str(dataset_2)
mean(dataset_2)
x <- 1:5
1:5
1:100
seq(from = 20, to = 50, by =3)
rep(21, times = 6)
seq(from = 20, to = 50, length.out=3)
x <- c(1, pi, 3)
y <- c(pi, pi, pi)
x == y
x != y
x > y
any(x == pi)
all(x == y)
dataset <- iris
dataset
dataset[1]
dataset[1,10]
head(dataset[1])
head(dataset[1],10)
dataset[1]
head(dataset[1],10)
dataset[1:3]
x <- c(1:100)
x
x[2]
x <- c(20:200)
x[2]
x < 2
x[x<2]
x[x < 24]
x < 24
x < 24
x[x < 24]
x[x < 24] #Gives you every value in x that is less than 24
x < 24
x < 24 #Vector is true when x is greater than 24
x %% 2 == 0
x[x %% 2 == 0] # Returns all the even x values
dataset[1]
dataset[1:3]
head(dataset[1],10)
x < 24 # Vector is true when x is greater than 24
x[x < 24] # Gives you every value in x that is less than 24
x %% 2 == 0 # Vector is true when x is even
x[x %% 2 == 0] # Returns all the even x values
x[ x > median(x) ]
x[ (x < quantile(x,0.05)) | (x > quantile(x,0.95)) ]
x[ !is.na(x) & !is.null(x) ]
x[ !is.na(x) & !is.null(x) ]
x[ !is.na(x) & !is.null(x) ]
x[ (x < quantile(x,0.05)) | (x > quantile(x,0.95)) ]
x[ abs(x-mean(x)) > 2*sd(x) ]
x[ abs(x-mean(x)) > 2*sd(x) ]
x[ abs(x-mean(x)) > 2*sd(x) ]
####################################################################################################################
# Selecting Vector Elements / Selecting Columns
####################################################################################################################
# Loading Iris Dataset
dataset <- iris
x <- c(20:200)
#############################
# Selecting Columns by [ ]
#############################
dataset[1]
dataset[1:3]
head(dataset[1],10)
#############################
# Indexing Technique
#############################
x < 24 # Vector is true when x is greater than 24
x[x < 24] # Gives you every value in x that is less than 24
x %% 2 == 0 # Vector is true when x is even
x[x %% 2 == 0] # Returns all the even x values
#############################
# Indexing Technique 2
#############################
# Select all elements greater than the median
x[ x > median(x) ]
# Select all elements in the lower and upper 5%
x[ (x < quantile(x,0.05)) | (x > quantile(x,0.95)) ]
# Select all elements that exceed Â±2 standard deviations from the mean
x[ abs(x-mean(x)) > 2*sd(x) ]
# Select all elements that are neither NA nor NULL
x[ !is.na(x) & !is.null(x) ]
x[ !is.na(x) & !is.null(x) ]
x[ is.na(x) & !is.null(x) ]
x[ !is.na(x) & !is.null(x) ]
dataset$Sepal.Length
dataset["Sepal.Length"]
dataset[1]
dataset[1:3]
head(dataset[1],10)
dataset$Sepal.Length
dataset["Sepal.Length"]
name(x) <- c("One", "Two")
names(x) <- c("One", "Two")
x
x[1]
x[2]
x[3]
x[1]
x["one"]
x["One"]
x$One
dataset[1]
dataset[1:3]
head(dataset[1],10)
x[1]
x$One
x["One"]
dataset$Sepal.Length
x$One
dataset["Sepal.Length"]
dataset$Sepal.Length
dataset["Sepal.Length"]
dataset$Sepal.Length
dataset["Sepal.Length"]
#Multiple Linear Regression
####################################################################################
# Plan & Key Terms:
####################################################################################
#Assumptions of Linear Regression
# 1. Linearity
# 2. Homoscedasticity
# 3. Multivariate normality
# 4. Independence of errror
# 5. Lack of multicollinearity - Dummy Variable Trap - Always omit 1 dummy variable - R stats package fixes the DVT automatically
#Building A Model
# 1. Backward Elimination
# 2. Select SL = .05
# 3. Add all variables in the model
# 4. Eliminate highest P value - If P value > SL ==> Remove Predictor - High P value menans its not significant
# 5. Stop when you have highest adjusted R Squared
# 6. Explain in units ==> R&D Spend has a greater impact on profit per unit of R&D spend than marketing has per unit marketing spend.
#Summary
# 1. Is model Statistically Significant? Check F Statistic
# 2. Are Coefficient significant? Check coeficcient t-Statistic & p-value or check the C.I
# 3. Is Model Useful? Check the adjusted R^2
# 4. Does Model fit the data well? Plot the residuals and check regression diagnostics
# 5. Does data satisfy assumption behind linear regression?
#Tips
# F1 to get help
# t-value = std / error ==> Measures the size of the difference relative to the variation in your sample data
####################################################################################
# Libraries
####################################################################################
library(MASS)
library(ISLR)
library(ggplot2)
library(car) #For VIF
####################################################################################
# Set the WD - Macs: /  -  Windows: \\
####################################################################################
setwd("/Users/kevin8523/Desktop/Windows Stuff Moved Over/Software Tools (Python, R, Tableau,etc)/ML/Machine Learning A-Z Template Folder/Part 2 - Regression/Section 5 - Multiple Linear Regression")
getwd()
####################################################################################
# Import the dataset:
####################################################################################
#Import the dataset
#dataset = read.csv('50_Startups.csv')
dataset = Boston # Public / Practice Dataset from library(MASS)
####################################################################################
# Analyze the data: Data Prep & Data Cleanse - You should usually split the dataset 80/20 or 70/30
####################################################################################
#Explore
?Boston
names(dataset)
str(dataset)
summary(dataset)
dim(dataset)
head(dataset)
####################################################################################
# Simple Linear Regression
####################################################################################
#Simple Linear Regression
lm.fit = lm(medv ~ lstat, data = dataset)
#Explore Fit of linear regression
lm.fit
summary(lm.fit) #summary table
#Additional Exploration functions
names(lm.fit) #list of functions stored in lm.fit
coef(lm.fit)
confint(lm.fit)
predict(lm.fit,data.frame(lstat=(c(5,10,15))),interval = "confidence")
predict(lm.fit,data.frame(lstat=(c(5,10,15))),interval = "prediction")
#Plot Data
plot(dataset$lstat,dataset$medv) #pch = 20
abline(lm.fit, lwd = 3, col ='red')
par(mfrow=c(2,2)) # adjusts the windows
plot(lm.fit) #Plots multiple charts
par(mfrow=c(1,1))
plot(predict(lm.fit),residuals(lm.fit))
plot(hatvalues(lm.fit))
which.max(hatvalues(lm.fit))
#Alternate plot type
# ggplot(data = dataset) +
#   geom_point(aes(x = lstat, y = medv))+
####################################################################################
# Multiple Linear Regression
####################################################################################
#Call Individual Variables
lm.fit = lm(medv ~ lstat + age, data = Boston)
summary(lm.fit)
#All Variables
lm.fit = lm(medv ~ ., data = Boston)
summary(lm.fit)
summary(lm.fit)$r.sq
vif(lm.fit)
summary(lm.fit)
df <- read.csv(url('http://bit.ly/imdbratings'))
df <- read.csv(url("http://bit.ly/imdbratings"))
df <- read.table("http://www.ats.ucla.edu/stat/examples/ara/angell.txt")
df <- read.table("http://bit.ly/imdbratings")
cwd()
getwd()
setwd("~/Desktop/Github/scripts")
getwd()
setwd("~/Desktop/Github/scripts/dataset")
getwd()
setwd("~/Desktop/Github/scripts/dataset")
setwd("~/Desktop/Github/scripts/R/dataset")
dataset <- read.csv("Future-500.csv")
View(dataset)
dataset <- read.csv("winequality-red.csv")
View(dataset)
dataset <- read.csv("winequality-red.csv", sep = ";" )
View(dataset)
df <- read.csv(url("http://bit.ly/imdbratings"))
dataset <- read.csv("winequality-red.csv", sep = ";" )
df <- read.table("http://bit.ly/imdbratings")
df <- read.csv(url("https://raw.githubusercontent.com/justmarkham/pandas-videos/master/data/imdb_1000.csv"))
View(df)
df <- read.table("https://raw.githubusercontent.com/justmarkham/pandas-videos/master/data/imdb_1000.csvs")
df <- read.csv(url("https://raw.githubusercontent.com/justmarkham/pandas-videos/master/data/imdb_1000.csv"))
df <- read.csv(url("https://raw.githubusercontent.com/justmarkham/pandas-videos/master/data/imdb_1000.csv"))
View(df)
head(df)
dataset
head(dataset)
dataset <- iris
df <- iris
head(df)
dataset <- dataset[c(4,1,2,3)]
head(df)
df <- df[c(4,1,2,3)]
head(df)
