{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "### Notebook by [Kevin Huang](https://kevin8523.github.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up dataset into a dataframe to practice ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data in a dataframe like a realworld problem\n",
    "df = pd.DataFrame(data = boston.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name columns\n",
    "df.columns = boston.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Price feature >> Target or Y Variable\n",
    "df[\"PRICE\"] = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Chas to Categorical for practice\n",
    "df['CHAS'] = df['CHAS'].replace([0], 'Charles River')\n",
    "df['CHAS'] = df['CHAS'].replace([1], 'Tract Bounds River')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.0    132\n",
       "5.0     115\n",
       "4.0     110\n",
       "3.0      38\n",
       "6.0      26\n",
       "8.0      24\n",
       "2.0      24\n",
       "1.0      20\n",
       "7.0      17\n",
       "Name: RAD, dtype: int64"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show values on a category\n",
    "df[\"RAD\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Description of Variables***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. CRIM - per capita crime rate by town\n",
    "2. ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "3. INDUS - proportion of non-retail business acres per town.\n",
    "4. CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
    "5. NOX - nitric oxides concentration (parts per 10 million)\n",
    "6. RM - average number of rooms per dwelling\n",
    "7. AGE - proportion of owner-occupied units built prior to 1940\n",
    "8. DIS - weighted distances to five Boston employment centres\n",
    "9. RAD - index of accessibility to radial highways\n",
    "10. TAX - full-value property-tax rate per 10,000\n",
    "11. PTRATIO - pupil-teacher ratio by town\n",
    "12. B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "13. LSTAT - % lower status of the population\n",
    "14. PRICE - Median value of owner-occupied homes in $1000's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Summary Statistics***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>Charles River</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>Charles River</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>Charles River</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>Charles River</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>Charles River</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS           CHAS    NOX     RM   AGE     DIS  RAD  \\\n",
       "0  0.00632  18.0   2.31  Charles River  0.538  6.575  65.2  4.0900  1.0   \n",
       "1  0.02731   0.0   7.07  Charles River  0.469  6.421  78.9  4.9671  2.0   \n",
       "2  0.02729   0.0   7.07  Charles River  0.469  7.185  61.1  4.9671  2.0   \n",
       "3  0.03237   0.0   2.18  Charles River  0.458  6.998  45.8  6.0622  3.0   \n",
       "4  0.06905   0.0   2.18  Charles River  0.458  7.147  54.2  6.0622  3.0   \n",
       "\n",
       "     TAX  PTRATIO       B  LSTAT  PRICE  \n",
       "0  296.0     15.3  396.90   4.98   24.0  \n",
       "1  242.0     17.8  396.90   9.14   21.6  \n",
       "2  242.0     17.8  392.83   4.03   34.7  \n",
       "3  222.0     18.7  394.63   2.94   33.4  \n",
       "4  222.0     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset: Train & test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only need to do this if you're manipulating the dataset (Filling missing data, transformation, etc). When splitting between the training and test set, you want to keep it separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.03445</td>\n",
       "      <td>82.5</td>\n",
       "      <td>2.03</td>\n",
       "      <td>Charles River</td>\n",
       "      <td>0.415</td>\n",
       "      <td>6.162</td>\n",
       "      <td>38.4</td>\n",
       "      <td>6.2700</td>\n",
       "      <td>2.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>393.77</td>\n",
       "      <td>7.43</td>\n",
       "      <td>24.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.56</td>\n",
       "      <td>Charles River</td>\n",
       "      <td>0.520</td>\n",
       "      <td>6.137</td>\n",
       "      <td>87.4</td>\n",
       "      <td>2.7147</td>\n",
       "      <td>5.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>394.47</td>\n",
       "      <td>13.44</td>\n",
       "      <td>19.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.04297</td>\n",
       "      <td>52.5</td>\n",
       "      <td>5.32</td>\n",
       "      <td>Charles River</td>\n",
       "      <td>0.405</td>\n",
       "      <td>6.565</td>\n",
       "      <td>22.9</td>\n",
       "      <td>7.3172</td>\n",
       "      <td>6.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>371.72</td>\n",
       "      <td>9.51</td>\n",
       "      <td>24.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03548</td>\n",
       "      <td>80.0</td>\n",
       "      <td>3.64</td>\n",
       "      <td>Charles River</td>\n",
       "      <td>0.392</td>\n",
       "      <td>5.876</td>\n",
       "      <td>19.1</td>\n",
       "      <td>9.2203</td>\n",
       "      <td>1.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>16.4</td>\n",
       "      <td>395.18</td>\n",
       "      <td>9.25</td>\n",
       "      <td>20.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.80230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>Charles River</td>\n",
       "      <td>0.740</td>\n",
       "      <td>5.854</td>\n",
       "      <td>96.6</td>\n",
       "      <td>1.8956</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>240.52</td>\n",
       "      <td>23.79</td>\n",
       "      <td>10.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM    ZN  INDUS           CHAS    NOX     RM   AGE     DIS   RAD  \\\n",
       "0   0.03445  82.5   2.03  Charles River  0.415  6.162  38.4  6.2700   2.0   \n",
       "1   0.21161   0.0   8.56  Charles River  0.520  6.137  87.4  2.7147   5.0   \n",
       "2   0.04297  52.5   5.32  Charles River  0.405  6.565  22.9  7.3172   6.0   \n",
       "3   0.03548  80.0   3.64  Charles River  0.392  5.876  19.1  9.2203   1.0   \n",
       "4  12.80230   0.0  18.10  Charles River  0.740  5.854  96.6  1.8956  24.0   \n",
       "\n",
       "     TAX  PTRATIO       B  LSTAT  PRICE  \n",
       "0  348.0     14.7  393.77   7.43   24.1  \n",
       "1  384.0     20.9  394.47  13.44   19.3  \n",
       "2  293.0     16.6  371.72   9.51   24.8  \n",
       "3  315.0     16.4  395.18   9.25   20.9  \n",
       "4  666.0     20.2  240.52  23.79   10.8  "
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomize dataset for split\n",
    "df = df.reindex(np.random.permutation(df.index)) # randomizes index\n",
    "df = df.sort_index() # sorts index \n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354, 14)\n",
      "(152, 14)\n"
     ]
    }
   ],
   "source": [
    "# Split dataset to train & test set\n",
    "train = df.iloc[:354, :]\n",
    "test = df.iloc[354:, :]\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup data for ML: Train set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Missing Data*** <br/>\n",
    "_Be sure to apply to both datasets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Taking care of missing data >> Array\n",
    "# from sklearn.preprocessing import Imputer\n",
    "# imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "# imputer = imputer.fit(X[:, 1:3])\n",
    "# X[:, 1:3] = imputer.transform(X[:, 1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Taking care of missing data >> Dataframe\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# imputer = SimpleImputer(strategy='constant', fill_value='MISSING')\n",
    "# train_imputed = imputer.fit_transform(train)\n",
    "# train_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Feature Scaling*** <br/>\n",
    "_Be sure to apply to both datasets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc_X = StandardScaler()\n",
    "# X_train = sc_X.fit_transform(X_train)\n",
    "# X_test = sc_X.transform(X_test)\n",
    "# sc_y = StandardScaler()\n",
    "# y_train = sc_y.fit_transform(y_train)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Encoding Categorical Variable*** <br/>\n",
    "Be sure to use n-1 to avoid the dummy variable trap <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Charles River</th>\n",
       "      <th>Tract Bounds River</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Charles River  Tract Bounds River\n",
       "0              1                   0\n",
       "1              1                   0\n",
       "2              1                   0\n",
       "3              1                   0\n",
       "4              1                   0\n",
       "5              1                   0\n",
       "6              1                   0\n",
       "7              1                   0\n",
       "8              1                   0\n",
       "9              1                   0"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Dummy Variables\n",
    "train_cat = pd.get_dummies(train['CHAS'])\n",
    "train_cat.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the dummy variables to the dataframe\n",
    "# train.join(categorical_variables) # Alternate: joins on index\n",
    "train = pd.concat([train,train_cat],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the unnesscary columns to avoid the dummy variable trap\n",
    "# axis=1: Columns ; axis=0: Rows\n",
    "train.drop(['CHAS','Tract Bounds River'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the Categorical Columns\n",
    "train.rename(columns = {'Charles River':'CHAS'},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder / Drop Columns\n",
    "list(train.columns.values)\n",
    "train = train[['CHAS',\n",
    " 'CRIM',\n",
    " 'ZN',\n",
    " 'INDUS',\n",
    " 'NOX',\n",
    " 'RM',\n",
    " 'AGE',\n",
    " 'DIS',\n",
    " 'RAD',\n",
    " 'TAX',\n",
    " 'PTRATIO',\n",
    " 'B',\n",
    " 'LSTAT',\n",
    " 'PRICE']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup data for ML: Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Repeat process for test set:***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Dummy Variables\n",
    "test_cat = pd.get_dummies(test['CHAS'])\n",
    "test_cat.head(10)\n",
    "# Add the dummy variables to the dataframe\n",
    "# train.join(categorical_variables) # Alternate: joins on index\n",
    "test = pd.concat([test,test_cat],axis=1)\n",
    "# Drop the unnesscary columns to avoid the dummy variable trap\n",
    "# axis=1: Columns ; axis=0: Rows\n",
    "test.drop(['CHAS','Tract Bounds River'],axis=1,inplace=True)\n",
    "# Rename the Categorical Columns\n",
    "test.rename(columns = {'Charles River':'CHAS'},inplace = True)\n",
    "# Reorder / Drop Columns\n",
    "list(test.columns.values)\n",
    "test = test[['CHAS',\n",
    " 'CRIM',\n",
    " 'ZN',\n",
    " 'INDUS',\n",
    " 'NOX',\n",
    " 'RM',\n",
    " 'AGE',\n",
    " 'DIS',\n",
    " 'RAD',\n",
    " 'TAX',\n",
    " 'PTRATIO',\n",
    " 'B',\n",
    " 'LSTAT',\n",
    " 'PRICE']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge data back together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 14)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append dataframe\n",
    "df = train.append(test)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep Data for Scikit & Apply ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split for X and y as vectors\n",
    "# : for the list >> [row selection, column seleciton]\n",
    "X = df.iloc[:, :-1].values # [:, :-1] >> [all rows, all columns except last one]\n",
    "y = df.iloc[:, 13].values # all rows and just column 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354, 13)\n",
      "(152, 13)\n",
      "(354,)\n",
      "(152,)\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3,\n",
    "                                                    random_state = 5,\n",
    "                                                    shuffle = False\n",
    "                                                   )\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on how you set up the data, will depend on the parameters for the train_test_split.\n",
    "\n",
    "***If you did not randomizes the dataset beforehand, you should set shuffle to true (could have some bias in the preset order). If you did shuffle the data before hand, set shuffle to false***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Apply ML***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Model\n",
    "lm = LinearRegression()\n",
    "\n",
    "# Fit data to model\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "y_pred = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.268447525889314\n"
     ]
    }
   ],
   "source": [
    "# Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7317500398946561\n",
      "0.7382994262101195\n"
     ]
    }
   ],
   "source": [
    "# Score\n",
    "print(lm.score(X_train,y_train))\n",
    "print(lm.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152,)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Visualize Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Prices vs Predicted prices: $Y_i$ vs $\\\\hat{Y}_i$')"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Visual\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"Prices: $Y_i$\")\n",
    "plt.ylabel(\"Predicted prices: $\\hat{Y}_i$\")\n",
    "plt.title(\"Prices vs Predicted prices: $Y_i$ vs $\\hat{Y}_i$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Model by building optimal model using Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].values # [:, :-1] >> [all rows, all columns except last one]\n",
    "y = df.iloc[:, 13].values # all rows and just column 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***For Backwards Elimination in statsmodels, it doesn't take into account the b0 constant term. We need to add it manually by adding the array 1 to our X***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.0000e+00, 1.0000e+00, 3.4450e-02, ..., 1.4700e+01, 3.9377e+02,\n",
       "        7.4300e+00],\n",
       "       [1.0000e+00, 1.0000e+00, 2.1161e-01, ..., 2.0900e+01, 3.9447e+02,\n",
       "        1.3440e+01],\n",
       "       [1.0000e+00, 1.0000e+00, 4.2970e-02, ..., 1.6600e+01, 3.7172e+02,\n",
       "        9.5100e+00],\n",
       "       ...,\n",
       "       [1.0000e+00, 1.0000e+00, 3.2264e-01, ..., 2.1200e+01, 3.7825e+02,\n",
       "        1.6900e+01],\n",
       "       [1.0000e+00, 1.0000e+00, 6.3796e-01, ..., 2.1000e+01, 3.8002e+02,\n",
       "        1.0260e+01],\n",
       "       [1.0000e+00, 1.0000e+00, 1.0233e+01, ..., 2.0200e+01, 3.7970e+02,\n",
       "        1.8030e+01]])"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.append(arr=X\n",
    "#          , values = np.ones(shape=(506,1)).astype(int)\n",
    "#          , axis=1) # Puts array 1 at the END of the the array X\n",
    "X_var = np.append(arr=np.ones(shape=(506,1)).astype(int)\n",
    "         , values = X\n",
    "         , axis = 1) # Flips it so array 1 is at the front of array X\n",
    "print(X_var.shape)\n",
    "X_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal Features for model >> Statisically sig. Variables\n",
    "X_opt = X_var[:,[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model again since we're using a diff library\n",
    "# Initialize the model\n",
    "regressor_OLS = sm.OLS(endog=y , exog=X_opt).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.741</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.734</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   108.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 13 Oct 2018</td> <th>  Prob (F-statistic):</th> <td>6.72e-135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:09:34</td>     <th>  Log-Likelihood:    </th> <td> -1498.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   3026.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   492</td>      <th>  BIC:               </th> <td>   3085.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   39.1462</td> <td>    5.153</td> <td>    7.597</td> <td> 0.000</td> <td>   29.023</td> <td>   49.270</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -2.6867</td> <td>    0.862</td> <td>   -3.118</td> <td> 0.002</td> <td>   -4.380</td> <td>   -0.994</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.1080</td> <td>    0.033</td> <td>   -3.287</td> <td> 0.001</td> <td>   -0.173</td> <td>   -0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0464</td> <td>    0.014</td> <td>    3.382</td> <td> 0.001</td> <td>    0.019</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0206</td> <td>    0.061</td> <td>    0.334</td> <td> 0.738</td> <td>   -0.100</td> <td>    0.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>  -17.7666</td> <td>    3.820</td> <td>   -4.651</td> <td> 0.000</td> <td>  -25.272</td> <td>  -10.262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    3.8099</td> <td>    0.418</td> <td>    9.116</td> <td> 0.000</td> <td>    2.989</td> <td>    4.631</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.0007</td> <td>    0.013</td> <td>    0.052</td> <td> 0.958</td> <td>   -0.025</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -1.4756</td> <td>    0.199</td> <td>   -7.398</td> <td> 0.000</td> <td>   -1.867</td> <td>   -1.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.3060</td> <td>    0.066</td> <td>    4.613</td> <td> 0.000</td> <td>    0.176</td> <td>    0.436</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0123</td> <td>    0.004</td> <td>   -3.280</td> <td> 0.001</td> <td>   -0.020</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -0.9527</td> <td>    0.131</td> <td>   -7.283</td> <td> 0.000</td> <td>   -1.210</td> <td>   -0.696</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.0093</td> <td>    0.003</td> <td>    3.467</td> <td> 0.001</td> <td>    0.004</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -0.5248</td> <td>    0.051</td> <td>  -10.347</td> <td> 0.000</td> <td>   -0.624</td> <td>   -0.425</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>178.041</td> <th>  Durbin-Watson:     </th> <td>   1.808</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 783.126</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.521</td>  <th>  Prob(JB):          </th> <td>8.84e-171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.281</td>  <th>  Cond. No.          </th> <td>1.52e+04</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.741\n",
       "Model:                            OLS   Adj. R-squared:                  0.734\n",
       "Method:                 Least Squares   F-statistic:                     108.1\n",
       "Date:                Sat, 13 Oct 2018   Prob (F-statistic):          6.72e-135\n",
       "Time:                        18:09:34   Log-Likelihood:                -1498.8\n",
       "No. Observations:                 506   AIC:                             3026.\n",
       "Df Residuals:                     492   BIC:                             3085.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         39.1462      5.153      7.597      0.000      29.023      49.270\n",
       "x1            -2.6867      0.862     -3.118      0.002      -4.380      -0.994\n",
       "x2            -0.1080      0.033     -3.287      0.001      -0.173      -0.043\n",
       "x3             0.0464      0.014      3.382      0.001       0.019       0.073\n",
       "x4             0.0206      0.061      0.334      0.738      -0.100       0.141\n",
       "x5           -17.7666      3.820     -4.651      0.000     -25.272     -10.262\n",
       "x6             3.8099      0.418      9.116      0.000       2.989       4.631\n",
       "x7             0.0007      0.013      0.052      0.958      -0.025       0.027\n",
       "x8            -1.4756      0.199     -7.398      0.000      -1.867      -1.084\n",
       "x9             0.3060      0.066      4.613      0.000       0.176       0.436\n",
       "x10           -0.0123      0.004     -3.280      0.001      -0.020      -0.005\n",
       "x11           -0.9527      0.131     -7.283      0.000      -1.210      -0.696\n",
       "x12            0.0093      0.003      3.467      0.001       0.004       0.015\n",
       "x13           -0.5248      0.051    -10.347      0.000      -0.624      -0.425\n",
       "==============================================================================\n",
       "Omnibus:                      178.041   Durbin-Watson:                   1.808\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              783.126\n",
       "Skew:                           1.521   Prob(JB):                    8.84e-171\n",
       "Kurtosis:                       8.281   Cond. No.                     1.52e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.52e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Backwards Elim process\n",
    "# >> Remove highest p-value until < .05 or satisfied\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.741</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.735</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   128.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 13 Oct 2018</td> <th>  Prob (F-statistic):</th> <td>5.54e-137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:09:34</td>     <th>  Log-Likelihood:    </th> <td> -1498.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   3022.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   494</td>      <th>  BIC:               </th> <td>   3072.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   39.0599</td> <td>    5.124</td> <td>    7.622</td> <td> 0.000</td> <td>   28.992</td> <td>   49.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -2.7187</td> <td>    0.854</td> <td>   -3.183</td> <td> 0.002</td> <td>   -4.397</td> <td>   -1.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.1084</td> <td>    0.033</td> <td>   -3.307</td> <td> 0.001</td> <td>   -0.173</td> <td>   -0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0458</td> <td>    0.014</td> <td>    3.390</td> <td> 0.001</td> <td>    0.019</td> <td>    0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>  -17.3760</td> <td>    3.535</td> <td>   -4.915</td> <td> 0.000</td> <td>  -24.322</td> <td>  -10.430</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    3.8016</td> <td>    0.406</td> <td>    9.356</td> <td> 0.000</td> <td>    3.003</td> <td>    4.600</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -1.4927</td> <td>    0.186</td> <td>   -8.037</td> <td> 0.000</td> <td>   -1.858</td> <td>   -1.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.2996</td> <td>    0.063</td> <td>    4.726</td> <td> 0.000</td> <td>    0.175</td> <td>    0.424</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -0.0118</td> <td>    0.003</td> <td>   -3.493</td> <td> 0.001</td> <td>   -0.018</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.9465</td> <td>    0.129</td> <td>   -7.334</td> <td> 0.000</td> <td>   -1.200</td> <td>   -0.693</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>    0.0093</td> <td>    0.003</td> <td>    3.475</td> <td> 0.001</td> <td>    0.004</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -0.5226</td> <td>    0.047</td> <td>  -11.019</td> <td> 0.000</td> <td>   -0.616</td> <td>   -0.429</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>178.430</td> <th>  Durbin-Watson:     </th> <td>   1.809</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 787.785</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.523</td>  <th>  Prob(JB):          </th> <td>8.60e-172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.300</td>  <th>  Cond. No.          </th> <td>1.48e+04</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.741\n",
       "Model:                            OLS   Adj. R-squared:                  0.735\n",
       "Method:                 Least Squares   F-statistic:                     128.2\n",
       "Date:                Sat, 13 Oct 2018   Prob (F-statistic):          5.54e-137\n",
       "Time:                        18:09:34   Log-Likelihood:                -1498.9\n",
       "No. Observations:                 506   AIC:                             3022.\n",
       "Df Residuals:                     494   BIC:                             3072.\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         39.0599      5.124      7.622      0.000      28.992      49.128\n",
       "x1            -2.7187      0.854     -3.183      0.002      -4.397      -1.040\n",
       "x2            -0.1084      0.033     -3.307      0.001      -0.173      -0.044\n",
       "x3             0.0458      0.014      3.390      0.001       0.019       0.072\n",
       "x4           -17.3760      3.535     -4.915      0.000     -24.322     -10.430\n",
       "x5             3.8016      0.406      9.356      0.000       3.003       4.600\n",
       "x6            -1.4927      0.186     -8.037      0.000      -1.858      -1.128\n",
       "x7             0.2996      0.063      4.726      0.000       0.175       0.424\n",
       "x8            -0.0118      0.003     -3.493      0.001      -0.018      -0.005\n",
       "x9            -0.9465      0.129     -7.334      0.000      -1.200      -0.693\n",
       "x10            0.0093      0.003      3.475      0.001       0.004       0.015\n",
       "x11           -0.5226      0.047    -11.019      0.000      -0.616      -0.429\n",
       "==============================================================================\n",
       "Omnibus:                      178.430   Durbin-Watson:                   1.809\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              787.785\n",
       "Skew:                           1.523   Prob(JB):                    8.60e-172\n",
       "Kurtosis:                       8.300   Cond. No.                     1.48e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.48e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimal Features for model >> Statisically sig. Variables\n",
    "X_opt = X_var[:,[0, 1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13]]\n",
    "\n",
    "# Create the model again since we're using a diff library\n",
    "# Initialize the model\n",
    "regressor_OLS = sm.OLS(endog=y , exog=X_opt).fit()\n",
    "\n",
    "# Begin Backwards Elimination >> Remove highest p-value\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using updated variables, re-run regression for the optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the dataframe to only select sig. variables\n",
    "df_v2 = df.iloc[:, :]\n",
    "df_v2 = df_v2.drop(['INDUS','AGE']\n",
    "          ,axis=1\n",
    "          ,inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHAS</th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.03445</td>\n",
       "      <td>82.5</td>\n",
       "      <td>0.415</td>\n",
       "      <td>6.162</td>\n",
       "      <td>6.2700</td>\n",
       "      <td>2.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>393.77</td>\n",
       "      <td>7.43</td>\n",
       "      <td>24.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.21161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520</td>\n",
       "      <td>6.137</td>\n",
       "      <td>2.7147</td>\n",
       "      <td>5.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>394.47</td>\n",
       "      <td>13.44</td>\n",
       "      <td>19.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.04297</td>\n",
       "      <td>52.5</td>\n",
       "      <td>0.405</td>\n",
       "      <td>6.565</td>\n",
       "      <td>7.3172</td>\n",
       "      <td>6.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>371.72</td>\n",
       "      <td>9.51</td>\n",
       "      <td>24.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.03548</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.392</td>\n",
       "      <td>5.876</td>\n",
       "      <td>9.2203</td>\n",
       "      <td>1.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>16.4</td>\n",
       "      <td>395.18</td>\n",
       "      <td>9.25</td>\n",
       "      <td>20.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>12.80230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.740</td>\n",
       "      <td>5.854</td>\n",
       "      <td>1.8956</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>240.52</td>\n",
       "      <td>23.79</td>\n",
       "      <td>10.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CHAS      CRIM    ZN    NOX     RM     DIS   RAD    TAX  PTRATIO       B  \\\n",
       "0     1   0.03445  82.5  0.415  6.162  6.2700   2.0  348.0     14.7  393.77   \n",
       "1     1   0.21161   0.0  0.520  6.137  2.7147   5.0  384.0     20.9  394.47   \n",
       "2     1   0.04297  52.5  0.405  6.565  7.3172   6.0  293.0     16.6  371.72   \n",
       "3     1   0.03548  80.0  0.392  5.876  9.2203   1.0  315.0     16.4  395.18   \n",
       "4     1  12.80230   0.0  0.740  5.854  1.8956  24.0  666.0     20.2  240.52   \n",
       "\n",
       "   LSTAT  PRICE  \n",
       "0   7.43   24.1  \n",
       "1  13.44   19.3  \n",
       "2   9.51   24.8  \n",
       "3   9.25   20.9  \n",
       "4  23.79   10.8  "
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm correct Columns removed\n",
    "df_v2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split for X and y as vectors\n",
    "# : for the list >> [row selection, column seleciton]\n",
    "X = df_v2.iloc[:, :-1].values # [:, :-1] >> [all rows, all columns except last one]\n",
    "y = df_v2.iloc[:, 11].values # all rows and just column 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354, 11)\n",
      "(152, 11)\n",
      "(354,)\n",
      "(152,)\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3,\n",
    "                                                    random_state = 5,\n",
    "                                                    shuffle = False\n",
    "                                                   )\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# Instantiate Model\n",
    "lm = LinearRegression()\n",
    "\n",
    "# Fit data to model\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "y_pred = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.487506228669723\n",
      "0.729860152720313\n",
      "0.7474771107047828\n"
     ]
    }
   ],
   "source": [
    "# Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(mse)\n",
    "\n",
    "# Score\n",
    "print(lm.score(X_train,y_train))\n",
    "print(lm.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
